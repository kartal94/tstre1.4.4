import asyncio
import time
import math
import os
from collections import defaultdict
from concurrent.futures import ProcessPoolExecutor
import multiprocessing

from pyrogram import Client, filters, enums
from pyrogram.types import Message
from pymongo import MongoClient, UpdateOne
from deep_translator import GoogleTranslator
import psutil

from Backend.helper.custom_filter import CustomFilters  # Owner filtresi i√ßin

# ----------------- Ortam Deƒüi≈ükenlerinden DATABASE -----------------
db_raw = os.getenv("DATABASE", "")
if not db_raw:
    raise Exception("DATABASE ortam deƒüi≈ükeni bulunamadƒ±!")

db_urls = [u.strip() for u in db_raw.split(",") if u.strip()]
if len(db_urls) < 2:
    raise Exception("ƒ∞kinci DATABASE bulunamadƒ±!")

MONGO_URL = db_urls[1]
client_db = MongoClient(MONGO_URL)
db_name = client_db.list_database_names()[0]
db = client_db[db_name]

movie_col = db["movie"]
series_col = db["tv"]

translator = GoogleTranslator(source='en', target='tr')
bot_start_time = time.time()
DOWNLOAD_DIR = "/"

# ----------------- Ortak Yardƒ±mcƒ± Fonksiyonlar -----------------
def dynamic_config():
    cpu_count = multiprocessing.cpu_count()
    ram_percent = psutil.virtual_memory().percent
    cpu_percent_val = psutil.cpu_percent(interval=0.5)

    if cpu_percent_val < 30:
        workers = min(cpu_count * 2, 16)
    elif cpu_percent_val < 60:
        workers = max(1, cpu_count)
    else:
        workers = 1

    if ram_percent < 40:
        batch = 80
    elif ram_percent < 60:
        batch = 40
    elif ram_percent < 75:
        batch = 20
    else:
        batch = 10

    return workers, batch

def translate_text_safe(text, cache):
    if not text or str(text).strip() == "":
        return ""
    if text in cache:
        return cache[text]
    try:
        tr = translator.translate(text)
    except Exception:
        tr = text
    cache[text] = tr
    return tr

def progress_bar(current, total, bar_length=12):
    if total == 0:
        return "[‚¨°" + "‚¨°"*(bar_length-1) + "] 0.00%"
    percent = (current / total) * 100
    filled_length = int(bar_length * current // total)
    bar = "‚¨¢" * filled_length + "‚¨°" * (bar_length - filled_length)
    return f"[{bar}] {percent:.2f}%"

# ----------------- /tur Komutu -----------------
genre_map = {
    "Action": "Aksiyon", "Film-Noir": "Kara Film", "Game-Show": "Oyun G√∂sterisi", "Short": "Kƒ±sa",
    "Sci-Fi": "Bilim Kurgu", "Sport": "Spor", "Adventure": "Macera", "Animation": "Animasyon",
    "Biography": "Biyografi", "Comedy": "Komedi", "Crime": "Su√ß", "Documentary": "Belgesel",
    "Drama": "Dram", "Family": "Aile", "News": "Haberler", "Fantasy": "Fantastik",
    "History": "Tarih", "Horror": "Korku", "Music": "M√ºzik", "Musical": "M√ºzikal",
    "Mystery": "Gizem", "Romance": "Romantik", "Science Fiction": "Bilim Kurgu",
    "TV Movie": "TV Filmi", "Thriller": "Gerilim", "War": "Sava≈ü", "Western": "Vah≈üi Batƒ±",
    "Action & Adventure": "Aksiyon ve Macera", "Kids": "√áocuklar", "Reality": "Ger√ßeklik",
    "Reality-TV": "Ger√ßeklik", "Sci-Fi & Fantasy": "Bilim Kurgu ve Fantazi", "Soap": "Pembe Dizi",
    "War & Politics": "Sava≈ü ve Politika", "Bilim-Kurgu": "Bilim Kurgu",
    "Aksiyon & Macera": "Aksiyon ve Macera", "Sava≈ü & Politik": "Sava≈ü ve Politika",
    "Bilim Kurgu & Fantazi": "Bilim Kurgu ve Fantazi", "Talk": "Talk-Show"
}

platform_genre_map = {
    "MAX": "Max", "Hbomax": "Max", "TABƒ∞ƒ∞": "Tabii", "NF": "Netflix", "DSNP": "Disney",
    "Tod": "Tod", "Blutv": "Max", "Tv+": "Tv+", "Exxen": "Exxen",
    "Gain": "Gain", "HBO": "Max", "Tabii": "Tabii", "AMZN": "Amazon",
}

@Client.on_message(filters.command("tur") & filters.private & CustomFilters.owner)
async def tur_ve_platform_duzelt(client: Client, message: Message):
    start_msg = await message.reply_text("üîÑ T√ºr ve platform g√ºncellemesi ba≈ülatƒ±ldƒ±‚Ä¶")
    collections = [(movie_col, "Filmler"), (series_col, "Diziler")]
    total_fixed = 0
    last_update = 0

    for col, name in collections:
        docs_cursor = col.find({}, {"_id": 1, "genres": 1, "telegram": 1, "seasons": 1})
        bulk_ops = []
        for doc in docs_cursor:
            doc_id = doc["_id"]
            genres = doc.get("genres", [])
            updated = False
            new_genres = [genre_map.get(g, g) for g in genres]
            if new_genres != genres:
                updated = True
            genres = new_genres

            for t in doc.get("telegram", []):
                name_field = t.get("name", "").lower()
                for key, genre_name in platform_genre_map.items():
                    if key.lower() in name_field and genre_name not in genres:
                        genres.append(genre_name)
                        updated = True

            for season in doc.get("seasons", []):
                for ep in season.get("episodes", []):
                    for t in ep.get("telegram", []):
                        name_field = t.get("name", "").lower()
                        for key, genre_name in platform_genre_map.items():
                            if key.lower() in name_field and genre_name not in genres:
                                genres.append(genre_name)
                                updated = True

            if updated:
                bulk_ops.append(UpdateOne({"_id": doc_id}, {"$set": {"genres": genres}}))
                total_fixed += 1

            if time.time() - last_update > 5:
                try:
                    await start_msg.edit_text(f"{name}: G√ºncellenen kayƒ±tlar: {total_fixed}")
                except:
                    pass
                last_update = time.time()

        if bulk_ops:
            col.bulk_write(bulk_ops)

    try:
        await start_msg.edit_text(
            f"‚úÖ T√ºr ve platform g√ºncellemesi tamamlandƒ±.\nToplam deƒüi≈ütirilen kayƒ±t: {total_fixed}",
            parse_mode=enums.ParseMode.MARKDOWN
        )
    except:
        pass

# ----------------- /cevir Komutu -----------------
def translate_batch_worker(batch):
    CACHE = {}
    results = []
    for doc in batch:
        _id = doc.get("_id")
        upd = {}
        desc = doc.get("description")
        if desc:
            upd["description"] = translate_text_safe(desc, CACHE)
        seasons = doc.get("seasons")
        if seasons:
            modified = False
            for season in seasons:
                for ep in season.get("episodes", []):
                    if "title" in ep and ep["title"]:
                        ep["title"] = translate_text_safe(ep["title"], CACHE)
                        modified = True
                    if "overview" in ep and ep["overview"]:
                        ep["overview"] = translate_text_safe(ep["overview"], CACHE)
                        modified = True
            if modified:
                upd["seasons"] = seasons
        results.append((_id, upd))
    return results

async def process_collection_parallel(collection, name, message):
    loop = asyncio.get_event_loop()
    total = collection.count_documents({})
    done = 0
    errors = 0
    start_time = time.time()
    last_update = 0
    ids_cursor = collection.find({}, {"_id": 1})
    ids = [d["_id"] for d in ids_cursor]
    idx = 0
    workers, batch_size = dynamic_config()
    pool = ProcessPoolExecutor(max_workers=workers)

    while idx < len(ids):
        batch_ids = ids[idx: idx + batch_size]
        batch_docs = list(collection.find({"_id": {"$in": batch_ids}}))
        if not batch_docs:
            break
        try:
            future = loop.run_in_executor(pool, translate_batch_worker, batch_docs)
            results = await future
        except Exception:
            errors += len(batch_docs)
            idx += len(batch_ids)
            await asyncio.sleep(1)
            continue
        for _id, upd in results:
            try:
                if upd:
                    collection.update_one({"_id": _id}, {"$set": upd})
                done += 1
            except Exception:
                errors += 1
        idx += len(batch_ids)
        elapsed = time.time() - start_time
        speed = done / elapsed if elapsed > 0 else 0
        remaining = total - done
        eta = remaining / speed if speed > 0 else float("inf")
        eta_str = time.strftime("%H:%M:%S", time.gmtime(eta)) if math.isfinite(eta) else "‚àû"
        cpu = psutil.cpu_percent(interval=None)
        ram_percent = psutil.virtual_memory().percent
        sys_info = f"CPU: {cpu}% | RAM: %{ram_percent}"
        if time.time() - last_update > 30 or idx >= len(ids):
            text = (
                f"{name}: {done}/{total}\n"
                f"{progress_bar(done, total)}\n\n"
                f"Kalan: {remaining}, Hatalar: {errors}\n"
                f"S√ºre: {eta_str}\n"
                f"{sys_info}"
            )
            try:
                await message.edit_text(text)
            except:
                pass
            last_update = time.time()
    pool.shutdown(wait=False)
    elapsed_time = round(time.time() - start_time, 2)
    return total, done, errors, elapsed_time

@Client.on_message(filters.command("cevir") & filters.private & CustomFilters.owner)
async def turkce_icerik(client: Client, message: Message):
    start_msg = await message.reply_text("üáπüá∑ T√ºrk√ße √ßeviri hazƒ±rlanƒ±yor.\nƒ∞lerleme tek mesajda g√∂sterilecektir.",
                                         parse_mode=enums.ParseMode.MARKDOWN)
    movie_total, movie_done, movie_errors, movie_time = await process_collection_parallel(movie_col, "Filmler", start_msg)
    series_total, series_done, series_errors, series_time = await process_collection_parallel(series_col, "Diziler", start_msg)

    total_all = movie_total + series_total
    done_all = movie_done + series_done
    errors_all = movie_errors + series_errors
    remaining_all = total_all - done_all
    total_time = round(movie_time + series_time, 2)
    hours, rem = divmod(total_time, 3600)
    minutes, seconds = divmod(rem, 60)
    eta_str = f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}"

    summary = (
        "üéâ T√ºrk√ße √áeviri Sonu√ßlarƒ±\n\n"
        f"üìå Filmler: {movie_done}/{movie_total}\n{progress_bar(movie_done, movie_total)}\nKalan: {movie_total - movie_done}, Hatalar: {movie_errors}\n\n"
        f"üìå Diziler: {series_done}/{series_total}\n{progress_bar(series_done, series_total)}\nKalan: {series_total - series_done}, Hatalar: {series_errors}\n\n"
        f"üìä Genel √ñzet\nToplam i√ßerik : {total_all}\nBa≈üarƒ±lƒ±     : {done_all - errors_all}\nHatalƒ±       : {errors_all}\nKalan        : {remaining_all}\nToplam s√ºre  : {eta_str}\n"
    )
    try:
        await start_msg.edit_text(summary, parse_mode=enums.ParseMode.MARKDOWN)
    except:
        pass

# ----------------- /istatistik Komutu -----------------
def get_db_stats_and_genres(url):
    client = MongoClient(url)
    db_name_list = client.list_database_names()
    if not db_name_list:
        return 0, 0, 0.0, 0.0, {}
    db_local = client[db_name_list[0]]
    total_movies = db_local["movie"].count_documents({})
    total_series = db_local["tv"].count_documents({})
    stats = db_local.command("dbstats")
    storage_mb = round(stats.get("storageSize", 0) / (1024*1024), 2)
    max_storage_mb = 512
    storage_percent = round((storage_mb / max_storage_mb) * 100, 1)
    genre_stats = defaultdict(lambda: {"film":0, "dizi":0})
    for doc in db_local["movie"].aggregate([{"$unwind":"$genres"},{"$group":{"_id":"$genres","count":{"$sum":1}}}]):
        genre_stats[doc["_id"]]["film"] = doc["count"]
    for doc in db_local["tv"].aggregate([{"$unwind":"$genres"},{"$group":{"_id":"$genres","count":{"$sum":1}}}]):
        genre_stats[doc["_id"]]["dizi"] = doc["count"]
    client.close()
    return total_movies, total_series, storage_mb, storage_percent, genre_stats

def get_system_status():
    cpu = round(psutil.cpu_percent(interval=None),1)
    ram = round(psutil.virtual_memory().percent,1)
    disk = psutil.disk_usage(DOWNLOAD_DIR)
    free_disk = round(disk.free/(1024**3),2)
    free_percent = round((disk.free/disk.total)*100,1)
    uptime_sec = int(time.time() - bot_start_time)
    h, rem = divmod(uptime_sec,3600)
    m, s = divmod(rem,60)
    uptime = f"{h}h {m}m {s}s"
    return cpu, ram, free_disk, free_percent, uptime

@Client.on_message(filters.command("istatistik") & filters.private & CustomFilters.owner)
async def send_statistics(client: Client, message: Message):
    try:
        if len(db_urls) < 2:
            await message.reply_text("‚ö†Ô∏è ƒ∞kinci veritabanƒ± bulunamadƒ±.")
            return
        total_movies, total_series, storage_mb, storage_percent, genre_stats = get_db_stats_and_genres(db_urls[1])
        cpu, ram, free_disk, free_percent, uptime = get_system_status()
        genre_lines = []
        for genre, counts in sorted(genre_stats.items(), key=lambda x:x[0]):
            genre_lines.append(f"{genre:<12} | Film: {counts['film']:<3} | Dizi: {counts['dizi']:<3}")
        genre_text = "\n".join(genre_lines)
        text = (
            f"‚å¨ <b>ƒ∞statistik</b>\n\n"
            f"‚î† Filmler: {total_movies}\n"
            f"‚î† Diziler: {total_series}\n"
            f"‚îñ Depolama: {storage_mb} MB ({storage_percent}%)\n\n"
            f"<b>T√ºr Bazlƒ±:</b>\n"
            f"<pre>{genre_text}</pre>\n\n"
            f"‚îü CPU ‚Üí {cpu}% | Bo≈ü ‚Üí {free_disk}GB [{free_percent}%]\n"
            f"‚îñ RAM ‚Üí {ram}% | S√ºre ‚Üí {uptime}"
        )
        await message.reply_text(text, parse_mode=enums.ParseMode.HTML, quote=True)
    except Exception as e:
        await message.reply_text(f"‚ö†Ô∏è Hata: {e}")
        print("istatistik hata:", e)
